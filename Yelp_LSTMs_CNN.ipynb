{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "with open('balanced_reviews.csv', 'wb') as data:\n",
    "    s3.download_fileobj('dlfinalproject', 'balanced_reviews.csv', data)\n",
    "df = pd.read_csv('balanced_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('my project_LSTMs_CNN.ipynb', 'dlfinalproject', 'my project.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>fun_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>cHdJXLlKNWixBXpDwEGb_A</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-01 16:30:00</td>\n",
       "      <td>7</td>\n",
       "      <td>6BnQwlxRn7ZuWdzninM9sQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>1</td>\n",
       "      <td>JSrP-dUmLlwZiI7Dp3PQ2A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Mem13A3C202RzT53npn4NA</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-05-13 10:41:43</td>\n",
       "      <td>6</td>\n",
       "      <td>IPw8yWiyqnfBzzWmypUHgg</td>\n",
       "      <td>5</td>\n",
       "      <td>If you are looking for the best pierogies in P...</td>\n",
       "      <td>9</td>\n",
       "      <td>5JVY32_bmTBfIGpCCsnAfw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>SU56w479vUfFHsvmvQIf7A</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-07-25 03:55:20</td>\n",
       "      <td>5</td>\n",
       "      <td>E4LqIZ7DJd_R4ZHSNKx4RQ</td>\n",
       "      <td>4</td>\n",
       "      <td>So good! They didn't make it to 5 stars due to...</td>\n",
       "      <td>7</td>\n",
       "      <td>DoRCeCcJbrsM2BiAKj3trA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>tjAeaGdxf7I4xN9M7wGJNQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-07-13 14:32:56</td>\n",
       "      <td>5</td>\n",
       "      <td>TaoaX7MqCujFRNaJBns2Sw</td>\n",
       "      <td>5</td>\n",
       "      <td>While the prices are a bit high for a make-you...</td>\n",
       "      <td>8</td>\n",
       "      <td>x37OyP--VEFE5p-xreplYA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246</td>\n",
       "      <td>FhIeCF6QrsLaRvAeu0oEPQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-24 06:42:29</td>\n",
       "      <td>5</td>\n",
       "      <td>3Qc49B7dA0ONmCxrn5iwCQ</td>\n",
       "      <td>2</td>\n",
       "      <td>OVERALL: The food isn't good (I explain below)...</td>\n",
       "      <td>13</td>\n",
       "      <td>2k8OVAPxlXHsA5X6EIoQpQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id  cool                 date  funny  \\\n",
       "0          17  cHdJXLlKNWixBXpDwEGb_A     1  2015-04-01 16:30:00      7   \n",
       "1          21  Mem13A3C202RzT53npn4NA     9  2017-05-13 10:41:43      6   \n",
       "2          62  SU56w479vUfFHsvmvQIf7A     6  2016-07-25 03:55:20      5   \n",
       "3         126  tjAeaGdxf7I4xN9M7wGJNQ     4  2014-07-13 14:32:56      5   \n",
       "4         246  FhIeCF6QrsLaRvAeu0oEPQ     4  2013-06-24 06:42:29      5   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  6BnQwlxRn7ZuWdzninM9sQ      3   \n",
       "1  IPw8yWiyqnfBzzWmypUHgg      5   \n",
       "2  E4LqIZ7DJd_R4ZHSNKx4RQ      4   \n",
       "3  TaoaX7MqCujFRNaJBns2Sw      5   \n",
       "4  3Qc49B7dA0ONmCxrn5iwCQ      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  I love chinese food and I love mexican food. W...       1   \n",
       "1  If you are looking for the best pierogies in P...       9   \n",
       "2  So good! They didn't make it to 5 stars due to...       7   \n",
       "3  While the prices are a bit high for a make-you...       8   \n",
       "4  OVERALL: The food isn't good (I explain below)...      13   \n",
       "\n",
       "                  user_id  fun_bin  \n",
       "0  JSrP-dUmLlwZiI7Dp3PQ2A        1  \n",
       "1  5JVY32_bmTBfIGpCCsnAfw        1  \n",
       "2  DoRCeCcJbrsM2BiAKj3trA        1  \n",
       "3  x37OyP--VEFE5p-xreplYA        1  \n",
       "4  2k8OVAPxlXHsA5X6EIoQpQ        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "'''from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df[['funny','text', 'fun_bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>text</th>\n",
       "      <th>fun_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>I love chinese food and I love mexican food. What can go wrong? A couple of things. First things first, this place is more of a \"rice bowl\" kind of place. I thought it was going to be more diverse as far as the menu goes, but its mainly rice bowls you get with different kinds of meats. The ordering was a little confusing at first, but one of the employees helped us out and I got the 2-item bowl and got the jade chicken and hengrenade chicken with all rice(jerk). I also ordered a jade chicken quesadilla on the side.\\n\\nI'm gonna admit, this place looks kinda dirty. I don't think Arizona uses those health department letter grade system like California does, but if I were to just judge by how it looked inside, i'd give it a \"C\" grade lol. We waited for about 15 minutes or so and finally got our food. We took it to go and ate at our hotel room. \\n\\nMmmm... the food was just alright. The jade chicken was nothing special. It tasted like any generic chinese fast food orange chicken/sesame chicken variant. The hengrenade chicken, although was the less spicier version of the jerk chicken, was still pretty spicy for me. Just be warned the jerk chicken is super spicy. If you aren't sure, ask for a sample at the restaurant before ordering, but it was way too spicy for me. \\n\\nThe jade chicken quesadilla was decent, but nothing special. Just imagine orange chicken in between a tortilla and cheese. A friend of mine ordered a jade chicken burrito and we were confused when we pulled it out of the bag because it was literally the size of Mcdonald's apple pie. If you order the burrito, be warned that it's a burrito for gnomes and smurfs, but he said it was tasty. \\n\\nThey provide a snicker doodle sugar cookie for each meal and it was decent, again nothing special. \\n\\nNot gonna lie, the next day my stomach felt like a little mexican dude and chinese dude were wrestling and throwing molotov cocktails inside. I used the bathroom like 5 times. I don't recommend eating this place if you have a lot to do the next day.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>If you are looking for the best pierogies in Pittsburgh, this is your place. There are a few small tables outside but most of the business is carry out. Pierogies Plus wins Best Pierogies every year. Why? Because the owner is from Poland and she is making the real deal pierogies. The best part is that they are hand pinched by a group of older Polish and Hungarian women. \\nThe biggest seller is potato and cheese but they sell many flavors. They are like plump pillows of softness. You can buy them buy the dozen. You can get them cold to take home and freeze or warm and ready to eat. The warm ones are served with butter and onions.  It's definitely a comfort food. The best part is that they ship internationally. Yes, they are that good.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>So good! They didn't make it to 5 stars due to the prices are a bit high for the amount of food and the location is a bit unsavory. \\nThe decor and atmosphere was surprisingly nice, from the outside I expected to be more run down inside. The staff was very nice. We were surprised how empty the dining room was for a Friday evening.\\nWe got Vegetable Samosas to start then ordered Chicken Tikka Masala, Lamb Rogan Josh, rice and plain Naan. Our only complaint was the lamb could've been more tender but everything was flavorful and delicious. \\nI would definitely go again if given the chance.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>While the prices are a bit high for a make-your-own pizza, the taste makes up for it. I love going to Seventh Street market, sitting Not Just Coffee and having a drink while waiting for delicious fresh made pizza from Pure.  I've taken this to go as well as eaten inside the market, and I can say that the pizza doesn't do well reheated. So try to eat it fresh while there if possible.\\n\\nIf one of their specialty pizzas sounds good to you, go for it, as those are definitely a better deal for the amount of toppings you get for the money.  I wanted what I wanted, though, so I ended up with a medium, thin crust, regular crust pizza with jalapenos, pepperoncini, onions and feta.  It was pretty expensive at $2/topping = $20 med pizza. But it was delicious.\\n\\nThe arugula salad with goat cheese and lemon vinaigrette is to-die-for. I crave that dressing days later. So light and fresh but flavorful.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>OVERALL: The food isn't good (I explain below), but this place may still be worth locals' time (and more importantly money).  Let me explain...\\n\\nThere are not many \"old\" restaurants in this town. We don't seem to value/frequent/patronize places that have been around putting out food for a long time. I think we should. Even when the food isn't show stopping. Why? This place has tremendous character and charm. There's an \"Old Western Vegas\" feel to Bob Taylor's. Established in 1955, it's the oldest restaurant in Las Vegas. Its a throwback to a rugged, carnivorous cowboy culture that has existed in this town for decades. And still exists. I did appreciate the slice of Vegas kitch that Bob Taylor's offers. \\n\\nFOOD ISSUES: So with all that charm how could this place go wrong? This place could be great. It really should be great. But they are not putting enough care into the food. I ordered the rib eye and asked for it to be medium rare. I was worried about it being overcooked and figured if a mistake was made, I'd be in the medium range. My instincts were correct. But the steak was closer to well done. In total, three steaks at our table were seriously overcooked. In a steakhouse. With a man tasked with grilling the steaks. Sigh. The fourth steak, smoked prime rib, was cooked properly. But the prime rib is cooked ahead if time, right? How was I prepared for this overcooked piece of meat? How did this only occasional red-meat-eater suspect that my steak would not be treated with attentive care? \\n\\nI'll tell you. When we walked in there was a large grill at the front of the restaurant with a number if steaks cooking on it. But the chef was not watching the meat. He wasn't even in front of the grill. He was nowhere to be seen as we walked through the doors. And there were at least 4 steaks cooking when we arrived. So I figured that my steak would receive the same lack of attention.  \\n\\nI ordered a simple naked potato and a side salad to accompany my steak. Both were fine. But there is not much room to mess up a potato and iceberg, is there? People rave about the garlic bread and I think it's because the rest of the meal is so mediocre, that the cheesy bread becomes the highlight if the meal. It was just OK. The most inexperienced cook could make it at home with sourdough, butter, and three types of cheese. \\n\\nA few people in our party ordered the mushroom rice side dish and it was not good. After tasting it, I was grateful to have passed on this wet, mush. \\n\\nSERVICE: Our waitress was very attentive and responsive. She was more than willing to return the overcooked steaks. \\n\\nI won't be back, but I'm glad to have visited this historic spot.\\n\\nService: 4 stars\\n\\nKitch: 4 stars\\n\\nFood: 1 star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  \\\n",
       "0  7       \n",
       "1  6       \n",
       "2  5       \n",
       "3  5       \n",
       "4  5       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0  I love chinese food and I love mexican food. What can go wrong? A couple of things. First things first, this place is more of a \"rice bowl\" kind of place. I thought it was going to be more diverse as far as the menu goes, but its mainly rice bowls you get with different kinds of meats. The ordering was a little confusing at first, but one of the employees helped us out and I got the 2-item bowl and got the jade chicken and hengrenade chicken with all rice(jerk). I also ordered a jade chicken quesadilla on the side.\\n\\nI'm gonna admit, this place looks kinda dirty. I don't think Arizona uses those health department letter grade system like California does, but if I were to just judge by how it looked inside, i'd give it a \"C\" grade lol. We waited for about 15 minutes or so and finally got our food. We took it to go and ate at our hotel room. \\n\\nMmmm... the food was just alright. The jade chicken was nothing special. It tasted like any generic chinese fast food orange chicken/sesame chicken variant. The hengrenade chicken, although was the less spicier version of the jerk chicken, was still pretty spicy for me. Just be warned the jerk chicken is super spicy. If you aren't sure, ask for a sample at the restaurant before ordering, but it was way too spicy for me. \\n\\nThe jade chicken quesadilla was decent, but nothing special. Just imagine orange chicken in between a tortilla and cheese. A friend of mine ordered a jade chicken burrito and we were confused when we pulled it out of the bag because it was literally the size of Mcdonald's apple pie. If you order the burrito, be warned that it's a burrito for gnomes and smurfs, but he said it was tasty. \\n\\nThey provide a snicker doodle sugar cookie for each meal and it was decent, again nothing special. \\n\\nNot gonna lie, the next day my stomach felt like a little mexican dude and chinese dude were wrestling and throwing molotov cocktails inside. I used the bathroom like 5 times. I don't recommend eating this place if you have a lot to do the next day.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  If you are looking for the best pierogies in Pittsburgh, this is your place. There are a few small tables outside but most of the business is carry out. Pierogies Plus wins Best Pierogies every year. Why? Because the owner is from Poland and she is making the real deal pierogies. The best part is that they are hand pinched by a group of older Polish and Hungarian women. \\nThe biggest seller is potato and cheese but they sell many flavors. They are like plump pillows of softness. You can buy them buy the dozen. You can get them cold to take home and freeze or warm and ready to eat. The warm ones are served with butter and onions.  It's definitely a comfort food. The best part is that they ship internationally. Yes, they are that good.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2  So good! They didn't make it to 5 stars due to the prices are a bit high for the amount of food and the location is a bit unsavory. \\nThe decor and atmosphere was surprisingly nice, from the outside I expected to be more run down inside. The staff was very nice. We were surprised how empty the dining room was for a Friday evening.\\nWe got Vegetable Samosas to start then ordered Chicken Tikka Masala, Lamb Rogan Josh, rice and plain Naan. Our only complaint was the lamb could've been more tender but everything was flavorful and delicious. \\nI would definitely go again if given the chance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "3  While the prices are a bit high for a make-your-own pizza, the taste makes up for it. I love going to Seventh Street market, sitting Not Just Coffee and having a drink while waiting for delicious fresh made pizza from Pure.  I've taken this to go as well as eaten inside the market, and I can say that the pizza doesn't do well reheated. So try to eat it fresh while there if possible.\\n\\nIf one of their specialty pizzas sounds good to you, go for it, as those are definitely a better deal for the amount of toppings you get for the money.  I wanted what I wanted, though, so I ended up with a medium, thin crust, regular crust pizza with jalapenos, pepperoncini, onions and feta.  It was pretty expensive at $2/topping = $20 med pizza. But it was delicious.\\n\\nThe arugula salad with goat cheese and lemon vinaigrette is to-die-for. I crave that dressing days later. So light and fresh but flavorful.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "4  OVERALL: The food isn't good (I explain below), but this place may still be worth locals' time (and more importantly money).  Let me explain...\\n\\nThere are not many \"old\" restaurants in this town. We don't seem to value/frequent/patronize places that have been around putting out food for a long time. I think we should. Even when the food isn't show stopping. Why? This place has tremendous character and charm. There's an \"Old Western Vegas\" feel to Bob Taylor's. Established in 1955, it's the oldest restaurant in Las Vegas. Its a throwback to a rugged, carnivorous cowboy culture that has existed in this town for decades. And still exists. I did appreciate the slice of Vegas kitch that Bob Taylor's offers. \\n\\nFOOD ISSUES: So with all that charm how could this place go wrong? This place could be great. It really should be great. But they are not putting enough care into the food. I ordered the rib eye and asked for it to be medium rare. I was worried about it being overcooked and figured if a mistake was made, I'd be in the medium range. My instincts were correct. But the steak was closer to well done. In total, three steaks at our table were seriously overcooked. In a steakhouse. With a man tasked with grilling the steaks. Sigh. The fourth steak, smoked prime rib, was cooked properly. But the prime rib is cooked ahead if time, right? How was I prepared for this overcooked piece of meat? How did this only occasional red-meat-eater suspect that my steak would not be treated with attentive care? \\n\\nI'll tell you. When we walked in there was a large grill at the front of the restaurant with a number if steaks cooking on it. But the chef was not watching the meat. He wasn't even in front of the grill. He was nowhere to be seen as we walked through the doors. And there were at least 4 steaks cooking when we arrived. So I figured that my steak would receive the same lack of attention.  \\n\\nI ordered a simple naked potato and a side salad to accompany my steak. Both were fine. But there is not much room to mess up a potato and iceberg, is there? People rave about the garlic bread and I think it's because the rest of the meal is so mediocre, that the cheesy bread becomes the highlight if the meal. It was just OK. The most inexperienced cook could make it at home with sourdough, butter, and three types of cheese. \\n\\nA few people in our party ordered the mushroom rice side dish and it was not good. After tasting it, I was grateful to have passed on this wet, mush. \\n\\nSERVICE: Our waitress was very attentive and responsive. She was more than willing to return the overcooked steaks. \\n\\nI won't be back, but I'm glad to have visited this historic spot.\\n\\nService: 4 stars\\n\\nKitch: 4 stars\\n\\nFood: 1 star   \n",
       "\n",
       "   fun_bin  \n",
       "0  1        \n",
       "1  1        \n",
       "2  1        \n",
       "3  1        \n",
       "4  1        "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import SnowballStemmer\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "#from spacymoji import Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 6.1MB/s ta 0:00:01\n",
      "\u001b[31mfastai 1.0.52 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-19.1.1\n"
     ]
    }
   ],
   "source": [
    "#Run two commands below and then restart the kernel\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy[cuda92]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/5b/0fab3fa533229436533fb504bb62f4cf7ea29541a487a9d1a0749876fc23/spacy-2.1.4-cp36-cp36m-manylinux1_x86_64.whl (29.8MB)\n",
      "\u001b[K     |████████████████████████████████| 29.8MB 59.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (2.20.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (1.15.4)\n",
      "Collecting blis<0.3.0,>=0.2.2 (from spacy[cuda92])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 44.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<1.1.0,>=0.0.5 (from spacy[cuda92])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/6c/2ef2d6f4c63a197981f4ac01bb17560c857c6721213c7c99998e48cdda2a/srsly-0.0.7-cp36-cp36m-manylinux1_x86_64.whl (180kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 52.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (0.9.6)\n",
      "Collecting wasabi<1.1.0,>=0.2.0 (from spacy[cuda92])\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/c1/d76ccdd12c716be79162d934fe7de4ac8a318b9302864716dde940641a79/wasabi-0.2.2-py3-none-any.whl\n",
      "Collecting thinc<7.1.0,>=7.0.2 (from spacy[cuda92])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/f1/3df317939a07b2fc81be1a92ac10bf836a1d87b4016346b25f8b63dee321/thinc-7.0.4-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema<3.1.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy[cuda92]) (2.6.0)\n",
      "Collecting thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda92\" (from spacy[cuda92])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/ad/11ab80a24bcedd7dd0cfabaedba2ceaeca11f1aaeeff432a3d2e63ca7d02/thinc_gpu_ops-0.0.4.tar.gz (483kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 48.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cupy-cuda92>=5.0.0b4; extra == \"cuda92\" (from spacy[cuda92])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/de/bea42293e151863e0d54908c2b5bce6476cb06df57e53c71ad6bfc3569f4/cupy_cuda92-7.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (320.7MB)\n",
      "\u001b[K     |████████████████████████████████| 320.7MB 153kB/s  eta 0:00:01     |████████████████████████████▎   | 283.9MB 1.7MB/s eta 0:00:22     |█████████████████████████████▍  | 294.6MB 23.0MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.2->spacy[cuda92]) (4.31.1)\n",
      "Collecting fastrlock>=0.3 (from cupy-cuda92>=5.0.0b4; extra == \"cuda92\"->spacy[cuda92])\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/93/a7efbd39eac46c137500b37570c31dedc2d31a8ff4949fcb90bda5bc5f16/fastrlock-0.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cupy-cuda92>=5.0.0b4; extra == \"cuda92\"->spacy[cuda92]) (1.11.0)\n",
      "Building wheels for collected packages: thinc-gpu-ops\n",
      "  Building wheel for thinc-gpu-ops (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/eb/ba/a3/9af9f326ed0d75a4540378af64a05a0e42be39d9b8513f3aea\n",
      "Successfully built thinc-gpu-ops\n",
      "\u001b[31mERROR: fastai 1.0.52 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: blis, srsly, wasabi, thinc, thinc-gpu-ops, fastrlock, cupy-cuda92, spacy\n",
      "  Found existing installation: thinc 6.12.1\n",
      "    Uninstalling thinc-6.12.1:\n",
      "      Successfully uninstalled thinc-6.12.1\n",
      "  Found existing installation: spacy 2.0.18\n",
      "    Uninstalling spacy-2.0.18:\n",
      "      Successfully uninstalled spacy-2.0.18\n",
      "Successfully installed blis-0.2.4 cupy-cuda92-7.0.0b1 fastrlock-0.4 spacy-2.1.4 srsly-0.0.7 thinc-7.0.4 thinc-gpu-ops-0.0.4 wasabi-0.2.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U spacy[cuda92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f4deed189e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import SnowballStemmer\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "#nlp = spacy.load(\"en\")\n",
    "#spacy.load('en')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "   # text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=\\(\\)]\", \" \", text) # keep punctuatuin, numnbers and letters\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" . \", text) #Add space to the dot\n",
    "    text = re.sub(r\"!\", \" ! \", text) #Add space to the exclamation sign\n",
    "    text = re.sub(r\":\", \" :\", text) #Add space before : sign\n",
    "    text = re.sub(r\";\", \" ;\", text) #Add space before ; sign\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    #text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    #text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    # find emojis\n",
    "    emoji_list = []\n",
    "    '''\n",
    "    for word in text.split():\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "    emoji_list'''\n",
    "    #text = text.split()\n",
    "\n",
    "    return text\n",
    "\n",
    "my_tok = spacy.load('en_core_web_sm')\n",
    "#emoji = Emoji(my_tok)\n",
    "#my_tok.add_pipe(emoji, first=True)\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(clean_text(x))]\n",
    "\n",
    "def remove_stop_words(tokens): return [tok for tok in tokens if tok not in spacy_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter()\n",
    "for sent in df_reviews['text']:\n",
    "    try:\n",
    "        counts.update(remove_stop_words(spacy_tok(sent)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'love': 32008,\n",
       "         'chinese': 7274,\n",
       "         'food': 133459,\n",
       "         'mexican': 6873,\n",
       "         '.': 1974798,\n",
       "         'wrong': 8025,\n",
       "         '?': 76651,\n",
       "         'couple': 10174,\n",
       "         'things': 14292,\n",
       "         'place': 106803,\n",
       "         '\"': 129623,\n",
       "         'rice': 20425,\n",
       "         'bowl': 9057,\n",
       "         'kind': 12303,\n",
       "         'thought': 13658,\n",
       "         'going': 23998,\n",
       "         'diverse': 493,\n",
       "         'far': 9426,\n",
       "         'menu': 44809,\n",
       "         'goes': 3716,\n",
       "         'mainly': 795,\n",
       "         'bowls': 1969,\n",
       "         'different': 14945,\n",
       "         'kinds': 1378,\n",
       "         'meats': 3860,\n",
       "         'ordering': 7141,\n",
       "         'little': 36265,\n",
       "         'confusing': 710,\n",
       "         'employees': 3579,\n",
       "         'helped': 1852,\n",
       "         'got': 45468,\n",
       "         '2': 31328,\n",
       "         '-': 245468,\n",
       "         'item': 3670,\n",
       "         'jade': 172,\n",
       "         'chicken': 47015,\n",
       "         'hengrenade': 4,\n",
       "         'rice(jerk': 1,\n",
       "         ')': 123431,\n",
       "         'ordered': 46914,\n",
       "         'quesadilla': 1020,\n",
       "         'gon': 1946,\n",
       "         'na': 2032,\n",
       "         'admit': 1717,\n",
       "         'looks': 5836,\n",
       "         'kinda': 2959,\n",
       "         'dirty': 3290,\n",
       "         'think': 26151,\n",
       "         'arizona': 1622,\n",
       "         'uses': 503,\n",
       "         'health': 1133,\n",
       "         'department': 557,\n",
       "         'letter': 199,\n",
       "         'grade': 641,\n",
       "         'system': 1403,\n",
       "         'like': 100970,\n",
       "         'california': 2161,\n",
       "         'judge': 870,\n",
       "         'looked': 11518,\n",
       "         'inside': 14168,\n",
       "         'c': 2908,\n",
       "         'lol': 4054,\n",
       "         'waited': 6480,\n",
       "         '15': 7979,\n",
       "         'minutes': 19781,\n",
       "         'finally': 9697,\n",
       "         'took': 17966,\n",
       "         'ate': 7847,\n",
       "         'hotel': 8862,\n",
       "         'room': 16149,\n",
       "         'mmmm': 370,\n",
       "         'alright': 1746,\n",
       "         'special': 13723,\n",
       "         'tasted': 12871,\n",
       "         'generic': 487,\n",
       "         'fast': 9896,\n",
       "         'orange': 3281,\n",
       "         'sesame': 1554,\n",
       "         'variant': 34,\n",
       "         'spicier': 301,\n",
       "         'version': 2904,\n",
       "         'jerk': 1158,\n",
       "         'pretty': 30651,\n",
       "         'spicy': 14967,\n",
       "         'warned': 870,\n",
       "         'super': 14835,\n",
       "         'sure': 22863,\n",
       "         'ask': 12023,\n",
       "         'sample': 1785,\n",
       "         'restaurant': 48074,\n",
       "         'way': 28102,\n",
       "         'decent': 9754,\n",
       "         'imagine': 2405,\n",
       "         'tortilla': 2161,\n",
       "         'cheese': 32083,\n",
       "         'friend': 14546,\n",
       "         'burrito': 5337,\n",
       "         'confused': 1352,\n",
       "         'pulled': 3380,\n",
       "         'bag': 2701,\n",
       "         'literally': 4737,\n",
       "         'size': 7473,\n",
       "         'mcdonald': 1107,\n",
       "         'apple': 2709,\n",
       "         'pie': 5039,\n",
       "         'order': 48094,\n",
       "         'gnomes': 5,\n",
       "         'smurfs': 3,\n",
       "         'said': 24055,\n",
       "         'tasty': 15704,\n",
       "         'provide': 1347,\n",
       "         'snicker': 41,\n",
       "         'doodle': 33,\n",
       "         'sugar': 3616,\n",
       "         'cookie': 2131,\n",
       "         'meal': 26281,\n",
       "         'lie': 750,\n",
       "         'day': 22010,\n",
       "         'stomach': 2253,\n",
       "         'felt': 8114,\n",
       "         'dude': 1410,\n",
       "         'wrestling': 67,\n",
       "         'throwing': 566,\n",
       "         'molotov': 3,\n",
       "         'cocktails': 3053,\n",
       "         'bathroom': 2828,\n",
       "         '5': 32471,\n",
       "         'times': 17038,\n",
       "         'recommend': 13037,\n",
       "         'eating': 13607,\n",
       "         'lot': 18196,\n",
       "         'looking': 14033,\n",
       "         'best': 34587,\n",
       "         'pierogies': 229,\n",
       "         'pittsburgh': 1755,\n",
       "         'small': 20935,\n",
       "         'tables': 12632,\n",
       "         'outside': 10634,\n",
       "         'business': 8170,\n",
       "         'carry': 1061,\n",
       "         'plus': 7138,\n",
       "         'wins': 235,\n",
       "         'year': 5782,\n",
       "         'owner': 7649,\n",
       "         'poland': 19,\n",
       "         'making': 6762,\n",
       "         'real': 7946,\n",
       "         'deal': 6639,\n",
       "         'hand': 5352,\n",
       "         'pinched': 12,\n",
       "         'group': 7708,\n",
       "         'older': 1392,\n",
       "         'polish': 500,\n",
       "         'hungarian': 79,\n",
       "         'women': 1449,\n",
       "         'biggest': 1371,\n",
       "         'seller': 78,\n",
       "         'potato': 7372,\n",
       "         'sell': 1471,\n",
       "         'flavors': 7565,\n",
       "         'plump': 376,\n",
       "         'pillows': 294,\n",
       "         'softness': 79,\n",
       "         'buy': 3288,\n",
       "         'dozen': 1627,\n",
       "         'cold': 9144,\n",
       "         'home': 14397,\n",
       "         'freeze': 145,\n",
       "         'warm': 7016,\n",
       "         'ready': 5595,\n",
       "         'eat': 30386,\n",
       "         'ones': 4166,\n",
       "         'served': 15751,\n",
       "         'butter': 7428,\n",
       "         'onions': 5978,\n",
       "         'definitely': 26300,\n",
       "         'comfort': 1524,\n",
       "         'ship': 188,\n",
       "         'internationally': 21,\n",
       "         'yes': 10985,\n",
       "         'good': 117194,\n",
       "         '!': 283341,\n",
       "         'stars': 16106,\n",
       "         'prices': 12021,\n",
       "         'bit': 22282,\n",
       "         'high': 10791,\n",
       "         'location': 17060,\n",
       "         'unsavory': 36,\n",
       "         'decor': 7211,\n",
       "         'atmosphere': 10454,\n",
       "         'surprisingly': 2125,\n",
       "         'nice': 36538,\n",
       "         'expected': 4275,\n",
       "         'run': 4752,\n",
       "         'staff': 22304,\n",
       "         'surprised': 4248,\n",
       "         'dining': 12917,\n",
       "         'friday': 4376,\n",
       "         'evening': 5566,\n",
       "         'vegetable': 1697,\n",
       "         'samosas': 328,\n",
       "         'start': 7520,\n",
       "         'tikka': 578,\n",
       "         'masala': 781,\n",
       "         'lamb': 4004,\n",
       "         'rogan': 38,\n",
       "         'josh': 169,\n",
       "         'plain': 2662,\n",
       "         'naan': 1316,\n",
       "         'complaint': 1835,\n",
       "         'tender': 7171,\n",
       "         'flavorful': 5940,\n",
       "         'delicious': 31418,\n",
       "         'given': 5666,\n",
       "         'chance': 3603,\n",
       "         'pizza': 29102,\n",
       "         'taste': 20473,\n",
       "         'makes': 8363,\n",
       "         'seventh': 38,\n",
       "         'street': 7518,\n",
       "         'market': 2657,\n",
       "         'sitting': 6016,\n",
       "         'coffee': 14191,\n",
       "         'having': 10176,\n",
       "         'drink': 18132,\n",
       "         'waiting': 8741,\n",
       "         'fresh': 27200,\n",
       "         'pure': 1035,\n",
       "         'taken': 3553,\n",
       "         'eaten': 4718,\n",
       "         'reheated': 310,\n",
       "         'try': 36831,\n",
       "         'possible': 2117,\n",
       "         'specialty': 1581,\n",
       "         'pizzas': 2767,\n",
       "         'sounds': 1786,\n",
       "         'better': 27075,\n",
       "         'toppings': 4740,\n",
       "         'money': 7811,\n",
       "         'wanted': 16420,\n",
       "         'ended': 6021,\n",
       "         'medium': 5247,\n",
       "         'thin': 4237,\n",
       "         'crust': 5614,\n",
       "         'regular': 6607,\n",
       "         'jalapenos': 715,\n",
       "         'pepperoncini': 71,\n",
       "         'feta': 991,\n",
       "         'expensive': 4942,\n",
       "         '$': 63173,\n",
       "         'topping': 1462,\n",
       "         '=': 8527,\n",
       "         '20': 9244,\n",
       "         'med': 252,\n",
       "         'arugula': 992,\n",
       "         'salad': 25640,\n",
       "         'goat': 1890,\n",
       "         'lemon': 3716,\n",
       "         'vinaigrette': 1106,\n",
       "         'die': 2255,\n",
       "         'crave': 782,\n",
       "         'dressing': 4197,\n",
       "         'days': 5683,\n",
       "         'later': 8043,\n",
       "         'light': 7455,\n",
       "         'overall': 12140,\n",
       "         ':': 69735,\n",
       "         '(': 116947,\n",
       "         'explain': 1513,\n",
       "         'worth': 14799,\n",
       "         'locals': 1360,\n",
       "         'time': 67587,\n",
       "         'importantly': 505,\n",
       "         'let': 13670,\n",
       "         'old': 12053,\n",
       "         'restaurants': 11243,\n",
       "         'town': 9628,\n",
       "         'value': 3215,\n",
       "         'frequent': 1216,\n",
       "         'patronize': 178,\n",
       "         'places': 13282,\n",
       "         'putting': 1476,\n",
       "         'long': 18249,\n",
       "         'stopping': 750,\n",
       "         'tremendous': 198,\n",
       "         'character': 543,\n",
       "         'charm': 685,\n",
       "         'western': 519,\n",
       "         'vegas': 24019,\n",
       "         'feel': 14140,\n",
       "         'bob': 351,\n",
       "         'taylor': 150,\n",
       "         'established': 195,\n",
       "         '1955': 16,\n",
       "         'oldest': 157,\n",
       "         'las': 8071,\n",
       "         'throwback': 97,\n",
       "         'rugged': 24,\n",
       "         'carnivorous': 89,\n",
       "         'cowboy': 341,\n",
       "         'culture': 530,\n",
       "         'existed': 264,\n",
       "         'decades': 250,\n",
       "         'exists': 245,\n",
       "         'appreciate': 2322,\n",
       "         'slice': 4089,\n",
       "         'kitch': 15,\n",
       "         'offers': 2424,\n",
       "         'issues': 1536,\n",
       "         'great': 70447,\n",
       "         'care': 6848,\n",
       "         'rib': 4483,\n",
       "         'eye': 3247,\n",
       "         'asked': 18357,\n",
       "         'rare': 3711,\n",
       "         'worried': 521,\n",
       "         'overcooked': 1835,\n",
       "         'figured': 1832,\n",
       "         'mistake': 1807,\n",
       "         'range': 1366,\n",
       "         'instincts': 41,\n",
       "         'correct': 1368,\n",
       "         'steak': 14831,\n",
       "         'closer': 1535,\n",
       "         'total': 3370,\n",
       "         'steaks': 1878,\n",
       "         'table': 29602,\n",
       "         'seriously': 5744,\n",
       "         'steakhouse': 1552,\n",
       "         'man': 6462,\n",
       "         'tasked': 14,\n",
       "         'grilling': 256,\n",
       "         'sigh': 490,\n",
       "         'fourth': 380,\n",
       "         'smoked': 3153,\n",
       "         'prime': 3014,\n",
       "         'cooked': 13453,\n",
       "         'properly': 1171,\n",
       "         'ahead': 2560,\n",
       "         'right': 27363,\n",
       "         'prepared': 4854,\n",
       "         'piece': 5057,\n",
       "         'meat': 21397,\n",
       "         'occasional': 362,\n",
       "         'red': 11031,\n",
       "         'eater': 842,\n",
       "         'suspect': 396,\n",
       "         'treated': 1553,\n",
       "         'attentive': 6221,\n",
       "         'tell': 9753,\n",
       "         'walked': 8147,\n",
       "         'large': 14044,\n",
       "         'grill': 4037,\n",
       "         'number': 3742,\n",
       "         'cooking': 2719,\n",
       "         'chef': 8683,\n",
       "         'watching': 2903,\n",
       "         'seen': 4869,\n",
       "         'doors': 1426,\n",
       "         '4': 21337,\n",
       "         'arrived': 7884,\n",
       "         'receive': 1218,\n",
       "         'lack': 2629,\n",
       "         'attention': 3082,\n",
       "         'simple': 5640,\n",
       "         'naked': 565,\n",
       "         'accompany': 315,\n",
       "         'fine': 7084,\n",
       "         'mess': 1957,\n",
       "         'iceberg': 385,\n",
       "         'people': 31083,\n",
       "         'rave': 862,\n",
       "         'garlic': 8259,\n",
       "         'bread': 17312,\n",
       "         'rest': 5144,\n",
       "         'mediocre': 3069,\n",
       "         'cheesy': 1647,\n",
       "         'highlight': 1082,\n",
       "         'ok': 13106,\n",
       "         'inexperienced': 94,\n",
       "         'cook': 4012,\n",
       "         'sourdough': 641,\n",
       "         'types': 2005,\n",
       "         'party': 7948,\n",
       "         'mushroom': 2929,\n",
       "         'dish': 18550,\n",
       "         'tasting': 4114,\n",
       "         'grateful': 311,\n",
       "         'passed': 1542,\n",
       "         'wet': 1067,\n",
       "         'mush': 255,\n",
       "         'service': 65730,\n",
       "         'waitress': 11720,\n",
       "         'responsive': 120,\n",
       "         'willing': 1575,\n",
       "         'return': 6642,\n",
       "         'wo': 8061,\n",
       "         'glad': 4676,\n",
       "         'visited': 2707,\n",
       "         'historic': 217,\n",
       "         'spot': 13307,\n",
       "         '1': 19230,\n",
       "         'star': 11676,\n",
       "         'compare': 1152,\n",
       "         'easy': 5085,\n",
       "         'maybe': 13521,\n",
       "         'find': 16330,\n",
       "         'ultimate': 481,\n",
       "         'sunday': 4794,\n",
       "         'morning': 4870,\n",
       "         'family': 9934,\n",
       "         'breakfast': 14855,\n",
       "         'drop': 1659,\n",
       "         'pals': 114,\n",
       "         'style': 9488,\n",
       "         'fries': 21508,\n",
       "         'expect': 6733,\n",
       "         '10': 17375,\n",
       "         'gave': 9048,\n",
       "         'waitresses': 1579,\n",
       "         'friendly': 23640,\n",
       "         'kick': 2738,\n",
       "         'big': 17223,\n",
       "         '~$12': 10,\n",
       "         'hungry': 5803,\n",
       "         'telling': 1621,\n",
       "         'end': 10153,\n",
       "         'want': 25977,\n",
       "         'lunch': 23712,\n",
       "         'usually': 9216,\n",
       "         'lindo': 68,\n",
       "         'michoacán': 2,\n",
       "         'sit': 7892,\n",
       "         'talked': 1022,\n",
       "         'husband': 8045,\n",
       "         'trying': 9371,\n",
       "         'juan': 165,\n",
       "         'hooked': 591,\n",
       "         'fajitas': 639,\n",
       "         'add': 6732,\n",
       "         'lots': 6512,\n",
       "         'flavor': 19154,\n",
       "         'loved': 9979,\n",
       "         'fideo': 29,\n",
       "         'soup': 15382,\n",
       "         'chips': 8524,\n",
       "         'peppers': 3623,\n",
       "         'salsa': 5767,\n",
       "         'bean': 3059,\n",
       "         'dip': 3287,\n",
       "         'favorite': 15265,\n",
       "         'gripe': 359,\n",
       "         'smelling': 314,\n",
       "         'fajita': 234,\n",
       "         'left': 12515,\n",
       "         'smelled': 1024,\n",
       "         'worked': 2481,\n",
       "         'clothes': 527,\n",
       "         'saturated': 154,\n",
       "         'smell': 2546,\n",
       "         'skin': 1793,\n",
       "         'greasy': 3587,\n",
       "         'noticed': 4300,\n",
       "         'cloud': 180,\n",
       "         'smoke': 2062,\n",
       "         'sat': 7601,\n",
       "         'planned': 704,\n",
       "         'par': 1859,\n",
       "         'packing': 151,\n",
       "         'febreeze': 6,\n",
       "         'extra': 9172,\n",
       "         'legendary': 228,\n",
       "         'iraqi': 7,\n",
       "         'fish': 13794,\n",
       "         'known': 2717,\n",
       "         'masgoof': 2,\n",
       "         'fan': 8005,\n",
       "         'dishes': 14979,\n",
       "         'delectable': 759,\n",
       "         'technique': 150,\n",
       "         'thousands': 180,\n",
       "         'years': 10089,\n",
       "         'iraq': 15,\n",
       "         'entire': 5320,\n",
       "         'evenly': 179,\n",
       "         'flayed': 1,\n",
       "         'open': 12129,\n",
       "         'nailed': 170,\n",
       "         'plank': 64,\n",
       "         'hickory': 125,\n",
       "         'wood': 1718,\n",
       "         'sprinkled': 559,\n",
       "         'olive': 1974,\n",
       "         'oil': 4016,\n",
       "         'tamarind': 252,\n",
       "         'paste': 765,\n",
       "         'placed': 2604,\n",
       "         '45': 2708,\n",
       "         'degree': 524,\n",
       "         'angle': 125,\n",
       "         'charcoal': 245,\n",
       "         'fire': 1959,\n",
       "         'traditionally': 174,\n",
       "         'freshwater': 29,\n",
       "         'chateau': 57,\n",
       "         'choice': 7253,\n",
       "         'tilapia': 247,\n",
       "         'method': 245,\n",
       "         'prepare': 1085,\n",
       "         'result': 716,\n",
       "         'charred': 844,\n",
       "         'surface': 232,\n",
       "         'juiciness': 96,\n",
       "         'trapped': 89,\n",
       "         'pleasure': 1021,\n",
       "         'enjoying': 1748,\n",
       "         'cases': 322,\n",
       "         'kabob': 421,\n",
       "         'houses': 427,\n",
       "         'boring': 1243,\n",
       "         'almighty': 27,\n",
       "         'come': 32450,\n",
       "         'middle': 4071,\n",
       "         'east': 2233,\n",
       "         'detroit': 164,\n",
       "         'europe': 198,\n",
       "         'hope': 3863,\n",
       "         'normally': 2744,\n",
       "         'ends': 842,\n",
       "         'disappointment': 1830,\n",
       "         'trip': 5166,\n",
       "         'iran': 24,\n",
       "         '2007': 91,\n",
       "         'paradise': 646,\n",
       "         'located': 6642,\n",
       "         'frankophilic': 1,\n",
       "         'metropolis': 20,\n",
       "         'montreal': 1459,\n",
       "         'maintaining': 79,\n",
       "         'washington': 204,\n",
       "         'dc': 240,\n",
       "         'need': 13198,\n",
       "         'cling': 10,\n",
       "         'shamshiri': 1,\n",
       "         'alboorz': 1,\n",
       "         'fix': 1922,\n",
       "         'gets': 5066,\n",
       "         'repetitive': 39,\n",
       "         'especially': 8709,\n",
       "         'single': 3630,\n",
       "         'house': 12009,\n",
       "         'region': 216,\n",
       "         'hold': 2138,\n",
       "         'candle': 365,\n",
       "         'therefor': 7,\n",
       "         'particularly': 1528,\n",
       "         'incumbent': 4,\n",
       "         'reach': 523,\n",
       "         'close': 7755,\n",
       "         'reigns': 36,\n",
       "         'supreme': 328,\n",
       "         'world': 4907,\n",
       "         'kabobs': 250,\n",
       "         'spices': 1592,\n",
       "         'superb': 1175,\n",
       "         'excellent': 12178,\n",
       "         'underappreciate': 1,\n",
       "         'techniques': 101,\n",
       "         'fluffy': 1839,\n",
       "         'velvety': 189,\n",
       "         'aromatic': 240,\n",
       "         'interiors': 119,\n",
       "         'décor': 752,\n",
       "         'persian': 243,\n",
       "         'arab': 24,\n",
       "         'sport': 212,\n",
       "         'gaudy': 68,\n",
       "         'hideous': 60,\n",
       "         'appears': 706,\n",
       "         'guys': 5345,\n",
       "         'tasteful': 202,\n",
       "         'enlisted': 8,\n",
       "         'help': 4807,\n",
       "         'actually': 14378,\n",
       "         'design': 1116,\n",
       "         'space': 5353,\n",
       "         'thoughtful': 267,\n",
       "         'layout': 804,\n",
       "         'pleasant': 3385,\n",
       "         'finishes': 70,\n",
       "         'aspiring': 32,\n",
       "         'eastern': 909,\n",
       "         'restauranteurs': 19,\n",
       "         'tend': 1099,\n",
       "         'interior': 2845,\n",
       "         'designers': 35,\n",
       "         'planet': 764,\n",
       "         'actual': 2210,\n",
       "         'hired': 175,\n",
       "         'designer': 145,\n",
       "         'company': 2168,\n",
       "         'pleasurable': 60,\n",
       "         'experience': 23913,\n",
       "         'revisiting': 51,\n",
       "         'hankering': 205,\n",
       "         'hats': 241,\n",
       "         'tending': 102,\n",
       "         'guests': 2201,\n",
       "         'nicest': 397,\n",
       "         'meet': 2092,\n",
       "         'debating': 173,\n",
       "         'writing': 1451,\n",
       "         'review': 13991,\n",
       "         'cupcakes': 590,\n",
       "         'excited': 3926,\n",
       "         'store': 5167,\n",
       "         'mall': 3693,\n",
       "         'cute': 4056,\n",
       "         'amicable': 34,\n",
       "         'overly': 2181,\n",
       "         'helpful': 3885,\n",
       "         'look': 11957,\n",
       "         'raspberry': 1033,\n",
       "         'coconut': 2724,\n",
       "         'key': 1474,\n",
       "         'lime': 1995,\n",
       "         'cake': 8082,\n",
       "         'pop': 2343,\n",
       "         'tried': 17275,\n",
       "         'gummy': 199,\n",
       "         'neon': 434,\n",
       "         'green': 9509,\n",
       "         'west': 2269,\n",
       "         'saw': 7423,\n",
       "         'bite': 8677,\n",
       "         'se': 358,\n",
       "         'bad': 19416,\n",
       "         'frosting': 529,\n",
       "         'appetizing': 591,\n",
       "         'closed': 3089,\n",
       "         'container': 1101,\n",
       "         'guess': 6779,\n",
       "         'spoiled': 527,\n",
       "         'yellow': 1375,\n",
       "         'color': 1162,\n",
       "         'citrus': 826,\n",
       "         'picture': 2044,\n",
       "         'grocery': 1265,\n",
       "         'garbage': 676,\n",
       "         'smoosh': 4,\n",
       "         'case': 4027,\n",
       "         'miranda': 28,\n",
       "         'moment': 2367,\n",
       "         'watched': 1234,\n",
       "         'sex': 393,\n",
       "         'city': 5181,\n",
       "         'know': 31357,\n",
       "         'tempted': 407,\n",
       "         'anymore': 1875,\n",
       "         'thankful': 254,\n",
       "         'whomever': 76,\n",
       "         'owns': 256,\n",
       "         'lucki': 27,\n",
       "         'thai': 8059,\n",
       "         'spelled': 140,\n",
       "         'y': 2190,\n",
       "         'sheesh': 71,\n",
       "         'embarrassing': 267,\n",
       "         'realize': 1736,\n",
       "         'intentional': 63,\n",
       "         'misspelling': 12,\n",
       "         'miss': 3418,\n",
       "         'marks': 332,\n",
       "         'opportuniti': 1,\n",
       "         'dine': 2938,\n",
       "         'carri': 1,\n",
       "         'deliveri': 1,\n",
       "         'stop': 8151,\n",
       "         'occasions': 957,\n",
       "         'months': 3035,\n",
       "         'matter': 2810,\n",
       "         'decide': 2066,\n",
       "         'disappointed': 7559,\n",
       "         'dined': 1379,\n",
       "         'tom': 929,\n",
       "         'yum': 3420,\n",
       "         'shrimp': 13537,\n",
       "         'crab': 8019,\n",
       "         'fried': 20808,\n",
       "         'consistently': 1262,\n",
       "         'staple': 695,\n",
       "         'hot': 22223,\n",
       "         'perfect': 14276,\n",
       "         'combination': 2486,\n",
       "         'sour': 3871,\n",
       "         'loaded': 1513,\n",
       "         'mushrooms': 4047,\n",
       "         'ample': 802,\n",
       "         'feeds': 94,\n",
       "         'perfectly': 7953,\n",
       "         'packed': 5232,\n",
       "         'shy': 343,\n",
       "         'egg': 9639,\n",
       "         'slut': 154,\n",
       "         'anthony': 310,\n",
       "         'bourdain': 120,\n",
       "         'pleased': 1728,\n",
       "         'mix': 3919,\n",
       "         'delivery': 2923,\n",
       "         'promised': 456,\n",
       "         'arrive': 1858,\n",
       "         'items': 12443,\n",
       "         'curries': 414,\n",
       "         'phenomenal': 1349,\n",
       "         'eggplant': 1832,\n",
       "         'entree': 3852,\n",
       "         'wish': 6160,\n",
       "         'stand': 3445,\n",
       "         'similar': 3024,\n",
       "         'gobble': 47,\n",
       "         'remember': 5948,\n",
       "         'particulars': 16,\n",
       "         'absolutely': 7138,\n",
       "         'huge': 12501,\n",
       "         'brown': 3101,\n",
       "         'option': 5158,\n",
       "         'upcharge': 200,\n",
       "         'wild': 1355,\n",
       "         'liked': 7941,\n",
       "         'rad': 143,\n",
       "         'laziness': 46,\n",
       "         'knows': 2381,\n",
       "         'bounds': 37,\n",
       "         'work': 10507,\n",
       "         'truly': 3402,\n",
       "         'shameful': 62,\n",
       "         'completely': 4543,\n",
       "         'thrilled': 552,\n",
       "         'beef': 18633,\n",
       "         'pad': 2258,\n",
       "         'ewe': 24,\n",
       "         'tough': 1953,\n",
       "         'chewy': 2470,\n",
       "         'misstep': 28,\n",
       "         'forgive': 263,\n",
       "         'instead': 8846,\n",
       "         'thing': 19314,\n",
       "         'gotten': 2055,\n",
       "         'nerves': 41,\n",
       "         'spice': 3682,\n",
       "         'consistency': 1420,\n",
       "         'started': 7917,\n",
       "         'level': 3903,\n",
       "         '6': 10930,\n",
       "         '7': 8677,\n",
       "         'normal': 2158,\n",
       "         'joints': 1270,\n",
       "         'settled': 841,\n",
       "         '8': 8850,\n",
       "         'burning': 510,\n",
       "         'hole': 1683,\n",
       "         'esophagus': 18,\n",
       "         'swallow': 184,\n",
       "         'getting': 10355,\n",
       "         'weeks': 2215,\n",
       "         'ago': 5467,\n",
       "         'zero': 1373,\n",
       "         'negatives': 178,\n",
       "         'frustrating': 353,\n",
       "         '9': 6294,\n",
       "         'category': 390,\n",
       "         'stops': 398,\n",
       "         'paying': 3294,\n",
       "         'probably': 14221,\n",
       "         'dumps': 37,\n",
       "         'barrel': 377,\n",
       "         'ghost': 335,\n",
       "         'chiles': 209,\n",
       "         'pan': 1915,\n",
       "         'alas': 641,\n",
       "         'simply': 3896,\n",
       "         'inconsistenci': 1,\n",
       "         'sorry': 4353,\n",
       "         'resist': 570,\n",
       "         'pita': 2305,\n",
       "         'jungle': 285,\n",
       "         'asu': 284,\n",
       "         'lived': 1916,\n",
       "         'apache': 140,\n",
       "         'live': 6008,\n",
       "         'arcadia': 215,\n",
       "         'area': 18229,\n",
       "         'difference': 1679,\n",
       "         'locations': 2202,\n",
       "         'stoned': 95,\n",
       "         'servers': 5808,\n",
       "         'usual': 2782,\n",
       "         'portabello': 73,\n",
       "         'burger': 22301,\n",
       "         'balsamic': 909,\n",
       "         'marinade': 249,\n",
       "         'use': 8082,\n",
       "         'fantastic': 6528,\n",
       "         'presentation': 2736,\n",
       "         'messy': 872,\n",
       "         'hits': 840,\n",
       "         'lips': 353,\n",
       "         'pass': 2800,\n",
       "         'new': 20473,\n",
       "         'potatoes': 7292,\n",
       "         'steamed': 2046,\n",
       "         'spinach': 3010,\n",
       "         'amazing': 20970,\n",
       "         'hummus': 2129,\n",
       "         'rocks': 801,\n",
       "         'split': 3068,\n",
       "         'roasted': 4226,\n",
       "         'bell': 1710,\n",
       "         'pepper': 4263,\n",
       "         'jalapeno': 1177,\n",
       "         'cilantro': 1823,\n",
       "         'sampler': 709,\n",
       "         'spotty': 226,\n",
       "         'comes': 10596,\n",
       "         'refills': 1677,\n",
       "         'incorrectly': 133,\n",
       "         'standard': 3643,\n",
       "         'expectation': 320,\n",
       "         'fulfilled': 95,\n",
       "         'baked': 4559,\n",
       "         'fact': 7052,\n",
       "         'substitution': 99,\n",
       "         'impressive': 1827,\n",
       "         'job': 4066,\n",
       "         'brfc': 6,\n",
       "         'solid': 4035,\n",
       "         'happy': 16134,\n",
       "         'recent': 1983,\n",
       "         'visits': 1988,\n",
       "         'combos': 577,\n",
       "         'juicy': 4655,\n",
       "         'crispy': 9392,\n",
       "         'sauces': 4323,\n",
       "         'enjoy': 11070,\n",
       "         'plan': 2198,\n",
       "         'returning': 2089,\n",
       "         'pros': 732,\n",
       "         '*': 26639,\n",
       "         '&': 27278,\n",
       "         'efficient': 1715,\n",
       "         'counter': 6650,\n",
       "         'clean': 10597,\n",
       "         'modern': 3043,\n",
       "         'plenty': 5462,\n",
       "         'seating': 7339,\n",
       "         'options': 9872,\n",
       "         'windows': 1123,\n",
       "         '\\n': 32440,\n",
       "         'tvs': 1098,\n",
       "         'football': 760,\n",
       "         'include': 1642,\n",
       "         'shoestring': 204,\n",
       "         'cup': 4561,\n",
       "         'coleslaw': 1192,\n",
       "         'skinny': 657,\n",
       "         'salty': 4850,\n",
       "         'plentiful': 892,\n",
       "         '|': 415,\n",
       "         'bland': 5043,\n",
       "         'crisp': 3169,\n",
       "         'crunch': 1777,\n",
       "         'seasoning': 2142,\n",
       "         'slight': 1022,\n",
       "         'dry': 7033,\n",
       "         'coating': 382,\n",
       "         'hint': 1449,\n",
       "         'cajun': 1110,\n",
       "         'breading': 736,\n",
       "         'overwhelming': 908,\n",
       "         'boylan': 34,\n",
       "         'soda': 2431,\n",
       "         'fountain': 1350,\n",
       "         'sweetened': 329,\n",
       "         'cane': 406,\n",
       "         'refillable': 54,\n",
       "         'iced': 2628,\n",
       "         'tea': 10755,\n",
       "         'honey': 3134,\n",
       "         'unsweetened': 154,\n",
       "         'milkshakes': 470,\n",
       "         'thick': 4412,\n",
       "         'creamy': 4670,\n",
       "         'orders': 6240,\n",
       "         'dipping': 2283,\n",
       "         'sauce': 34361,\n",
       "         'wildflower': 89,\n",
       "         'chipotle': 2217,\n",
       "         'wasabi': 980,\n",
       "         'tenders': 736,\n",
       "         'habanero': 415,\n",
       "         'brbbq': 3,\n",
       "         'barbecue': 838,\n",
       "         'box': 3208,\n",
       "         'm': 3490,\n",
       "         'f': 1354,\n",
       "         '11': 5030,\n",
       "         'pm': 8011,\n",
       "         '3': 27162,\n",
       "         'wings': 7867,\n",
       "         'bucks': 2634,\n",
       "         'cons': 738,\n",
       "         'pricey': 3172,\n",
       "         'essentially': 721,\n",
       "         'priced': 4201,\n",
       "         'higher': 1991,\n",
       "         'joint': 4403,\n",
       "         'person': 8270,\n",
       "         'quality': 14911,\n",
       "         'upscale': 1553,\n",
       "         'casual': 2937,\n",
       "         '2017': 475,\n",
       "         'david': 493,\n",
       "         'carradine': 1,\n",
       "         'lobster': 6584,\n",
       "         'spaghetti': 1437,\n",
       "         'heard': 5109,\n",
       "         'toast': 5138,\n",
       "         'dinner': 23366,\n",
       "         '30pm': 1020,\n",
       "         'night': 26183,\n",
       "         'half': 13212,\n",
       "         'filled': 5221,\n",
       "         'seats': 2579,\n",
       "         'seated': 9255,\n",
       "         'bathrooms': 1133,\n",
       "         'door': 7598,\n",
       "         'wanting': 1986,\n",
       "         'difficult': 1796,\n",
       "         'affecting': 20,\n",
       "         'draft': 859,\n",
       "         'patio': 6568,\n",
       "         'constant': 396,\n",
       "         'politely': 535,\n",
       "         'hostess': 4297,\n",
       "         'obliged': 128,\n",
       "         'server': 19573,\n",
       "         'continued': 836,\n",
       "         'wait': 24677,\n",
       "         'lose': 868,\n",
       "         'brought': 8856,\n",
       "         'loaf': 484,\n",
       "         'soft': 6849,\n",
       "         'sweet': 20309,\n",
       "         'zest': 176,\n",
       "         'told': 14875,\n",
       "         'ricotta': 1041,\n",
       "         'ravioli': 1178,\n",
       "         'happened': 3112,\n",
       "         'eyeing': 140,\n",
       "         'substitute': 538,\n",
       "         'lasagna': 791,\n",
       "         'friends': 14274,\n",
       "         'pot': 2894,\n",
       "         'white': 9152,\n",
       "         'marsala': 273,\n",
       "         'came': 40071,\n",
       "         'changed': 2556,\n",
       "         'beans': 6311,\n",
       "         'mashed': 2464,\n",
       "         'meals': 4407,\n",
       "         'found': 11616,\n",
       "         'um': 751,\n",
       "         'okay': 7949,\n",
       "         'forward': 3525,\n",
       "         'rich': 3852,\n",
       "         'bits': 1292,\n",
       "         'finish': 4342,\n",
       "         'tasteless': 1179,\n",
       "         'cream': 14218,\n",
       "         'watery': 880,\n",
       "         'main': 6035,\n",
       "         'bright': 1907,\n",
       "         'salads': 4135,\n",
       "         'enjoyed': 11483,\n",
       "         'blue': 3476,\n",
       "         'wedge': 530,\n",
       "         'portion': 7523,\n",
       "         'bacon': 11054,\n",
       "         'disappeared': 457,\n",
       "         'lady': 4380,\n",
       "         'refilling': 324,\n",
       "         'waters': 745,\n",
       "         'checks': 557,\n",
       "         'leaving': 2281,\n",
       "         'bar': 30441,\n",
       "         'playing': 2771,\n",
       "         'phone': 3397,\n",
       "         'chatting': 620,\n",
       "         'pretentious': 693,\n",
       "         'impressed': 4950,\n",
       "         ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# WHat is the 99% quantile of  length of the sentence?\n",
    "\n",
    "df_reviews['len_text'] = df_reviews['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['len_text'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that spacy_tok takes a while run it just once\n",
    "def encode_sentence(sent, vocab2index, N=500, padding_start=True):\n",
    "    \"Encoding a sentence adding padding\"\n",
    "    x = remove_stop_words(spacy_tok(sent))\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[:l] = enc1[:l]\n",
    "    else:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    return enc, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_reviews['text'], df_reviews['fun_bin'], test_size=0.2, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_valid.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_valid.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120401,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset(Dataset):\n",
    "    def __init__(self, df, y, N=400, padding_start=True):\n",
    "        self.df = df\n",
    "        self.X = [encode_sentence(sent, vocab2index, N, padding_start) for sent in self.df]\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, s = self.X[idx]\n",
    "        return x, s, self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  YelpDataset(X_train, y_train, padding_start=False)\n",
    "valid_ds =  YelpDataset(X_valid, y_valid, padding_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[118582]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg=[]\n",
    "i=0\n",
    "for x,s,y in train_ds:\n",
    "    if s <=0:\n",
    "        neg.append(i)\n",
    "    i+=1\n",
    "\n",
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neither'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[118582,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(index = 118582, inplace=True)\n",
    "y_train.drop(index = 118582, inplace=True)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMV0Model,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        out_pack, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs_v0(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            # s is not used in this model\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics_v0(model, valid_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics_v0(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        # s is not used here\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().cuda().unsqueeze(1)\n",
    "        y_hat = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133541\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model_v0 = LSTMV0Model(vocab_size, 100, 100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.480 val loss 0.531 and val accuracy 0.727\n",
      "train loss 0.426 val loss 0.573 and val accuracy 0.738\n",
      "train loss 0.467 val loss 0.551 and val accuracy 0.748\n",
      "train loss 0.417 val loss 0.570 and val accuracy 0.750\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model_v0, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_v0,\"lstmv0_lr0.01_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.495 val loss 0.511 and val accuracy 0.752\n",
      "train loss 0.413 val loss 0.509 and val accuracy 0.772\n"
     ]
    }
   ],
   "source": [
    "model_v0 = LSTMV0Model(vocab_size, 100, 100).cuda()\n",
    "train_epocs_v0(model_v0, epochs=10, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_v0,\"lstmv0_lr0.005_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.537 val loss 0.974 and val accuracy 0.558\n",
      "train loss 0.465 val loss 0.718 and val accuracy 0.634\n",
      "train loss 0.431 val loss 0.911 and val accuracy 0.601\n",
      "train loss 0.407 val loss 0.968 and val accuracy 0.600\n"
     ]
    }
   ],
   "source": [
    "model_v0 = LSTMV0Model(vocab_size, 100, 100).cuda()\n",
    "train_epocs_v0(model_v0, epochs=20, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_v0,\"lstmv0_lr0.001_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM v1: Model with variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with padding at the end\n",
    "train_ds_2 =  YelpDataset(X_train, y_train, padding_start=True)\n",
    "valid_ds_2 =  YelpDataset(X_valid, y_valid, padding_start=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        # sorting\n",
    "        s, sort_index = torch.sort(s.float(), 0,descending=True) # s is the length of the sentence. Sort these lengths\n",
    "        s = s.numpy().tolist() # \n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True) # We want LSTM to forget the padding, but in order to apply \n",
    "        #ordering mini batches withtin the model\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack) \n",
    "        out = self.linear(ht[-1]) # Problem here is that output is not sorted! \n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out) # scatter_ is undoing the sorting with the given sorting index\n",
    "        # kind of sorting back with the original indexing\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x, s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, val_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in val_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().cuda().unsqueeze(1)\n",
    "        y_hat = model(x, s)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds_2, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds_2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133541\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "modelv1 = LSTMModel(vocab_size, 100, 100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.603 val loss 0.591 and val accuracy 0.726\n",
      "train loss 0.530 val loss 0.520 and val accuracy 0.758\n",
      "train loss 0.434 val loss 0.524 and val accuracy 0.741\n",
      "train loss 0.393 val loss 0.494 and val accuracy 0.769\n"
     ]
    }
   ],
   "source": [
    "train_epocs(modelv1, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(modelv1,\"lstmv1_lr0.01_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.355 val loss 0.494 and val accuracy 0.777\n",
      "train loss 0.333 val loss 0.515 and val accuracy 0.771\n",
      "train loss 0.310 val loss 0.525 and val accuracy 0.771\n",
      "train loss 0.287 val loss 0.556 and val accuracy 0.772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_epocs(modelv1, epochs=20, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(modelv1, 'lstmv1_lr0.005_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.267 val loss 0.577 and val accuracy 0.766\n",
      "train loss 0.263 val loss 0.583 and val accuracy 0.766\n",
      "train loss 0.257 val loss 0.588 and val accuracy 0.766\n",
      "train loss 0.253 val loss 0.603 and val accuracy 0.766\n"
     ]
    }
   ],
   "source": [
    "train_epocs(modelv1, epochs=20, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(modelv1, 'lstmv1_lr0.001_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "    \n",
    "        self.conv_3 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=3)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=4)\n",
    "        self.conv_5 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x3 = F.relu(self.conv_3(x))\n",
    "        x4 = F.relu(self.conv_4(x))\n",
    "        x5 = F.relu(self.conv_5(x))\n",
    "        x3 = nn.MaxPool1d(kernel_size = 398)(x3)\n",
    "        x4 = nn.MaxPool1d(kernel_size = 397)(x4)\n",
    "        x5 = nn.MaxPool1d(kernel_size = 396)(x5)\n",
    "        out = torch.cat([x3, x4, x5], 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133541\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = CNNModel(vocab_size, 300).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([400, 400])\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "for x,s,y in train_dl:\n",
    "    print(x.shape)\n",
    "    x = x.long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "y_hat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(m, val_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in val_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().cuda().unsqueeze(1)\n",
    "        y_hat = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, val_dl)\n",
    "        #if i % 1 == 1:\n",
    "        print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133541\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.471 val loss 0.475 and val accuracy 0.778\n",
      "train loss 0.171 val loss 1.093 and val accuracy 0.745\n",
      "train loss 0.083 val loss 2.173 and val accuracy 0.732\n",
      "train loss 0.073 val loss 3.152 and val accuracy 0.729\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(vocab_size, 300).cuda()\n",
    "train_epocs(model, epochs=20, lr=0.005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'cnn_lr0.005_20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.057 val loss 5.499 and val accuracy 0.721\n",
      "train loss 0.063 val loss 6.818 and val accuracy 0.723\n",
      "train loss 0.057 val loss 6.528 and val accuracy 0.724\n",
      "train loss 0.052 val loss 6.233 and val accuracy 0.721\n",
      "train loss 0.059 val loss 6.430 and val accuracy 0.726\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(vocab_size, 300).cuda()\n",
    "train_epocs(model, epochs=5, lr=0.005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'cnn_lr0.005_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.559 val loss 0.489 and val accuracy 0.768\n",
      "train loss 0.493 val loss 0.472 and val accuracy 0.779\n",
      "train loss 0.459 val loss 0.464 and val accuracy 0.781\n",
      "train loss 0.429 val loss 0.465 and val accuracy 0.782\n",
      "train loss 0.398 val loss 0.470 and val accuracy 0.782\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(vocab_size, 300).cuda()\n",
    "train_epocs(model, epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'cnn_lr0.001_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel2(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super(CNNModel2, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "    \n",
    "        self.conv_3 = nn.Conv1d(in_channels=hidden_dim, out_channels=150, kernel_size=30)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=hidden_dim, out_channels=150, kernel_size=40)\n",
    "        #self.conv_5 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x3 = F.relu(self.conv_3(x))\n",
    "        x4 = F.relu(self.conv_4(x))\n",
    "       # x5 = F.relu(self.conv_5(x))\n",
    "        x3 = nn.MaxPool1d(kernel_size = 371)(x3)\n",
    "        x4 = nn.MaxPool1d(kernel_size = 361)(x4)\n",
    "       # x5 = nn.MaxPool1d(kernel_size = 396)(x5)\n",
    "        out = torch.cat([x3, x4], 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133541\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model2 = CNNModel2(vocab_size, 300).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.727 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.458 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.384 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.304 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.242 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.200 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.187 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.168 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.172 val loss 0.470 and val accuracy 0.782\n",
      "train loss 0.165 val loss 0.470 and val accuracy 0.782\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model2, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model2, 'cnn2_lr0.01_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
